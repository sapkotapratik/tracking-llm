# tracking-llm
Monitoring the developments in large language model advancement. 

<b>Karpathy's Video Summary: </b>

<b>Objective:</b> Next work prediction (but it is very powerful)

The networks "dreams" internet documents.

- n/w is dreaming on text form the distribution that it was trained on
-  it's mimicking these docs but this is all kind of like hallucinated
-  it's parroting the training dataset distributions


  <b> Problems </b>

- reversal curse (eg. Tom cruise's mother and vice-versa)


  <b>Recommendations: </b>
  - Finetuning (cheaper) since pretraining would be costlier
  -  Q/A response generator
  -  RLHF (also 
  -  multimodality
  -  Metrics: eg. Elo Rating
  - Thinking Fast and Slow ( system 1 vs system 2 thinking)
  -  RAG (Retrieval Augmentation Generation)
  -  Custom LLMs
 
    <b>  LLM Security: </b>
  -   Jailbreak
  -   prompt injection Solution: https://github.com/protectai/rebuff (LLM Prompt Injection Detector)



## Amazing Repos:

- https://github.com/logspace-ai/langflow
- https://github.com/SJTU-IPADS/PowerInfer
- https://github.com/langfuse/langfuse
- https://github.com/facebookresearch/llama-recipes
- https://github.com/uber-archive/plato-research-dialogue-system
- https://github.com/jmorganca/ollama



